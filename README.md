# ğŸš² Proyecto de IntegraciÃ³n con API y MongoDB!

Este proyecto consta de dos scripts en Python que interactÃºan con una API, almacenan datos en una base de datos MongoDB y exportan estos datos a diferentes formatos. El objetivo es recoger informaciÃ³n sobre el estado de las bicicletas en diferentes ubicaciones a travÃ©s de una API, almacenarlos en MongoDB y luego procesar y exportar esos datos usando **pandas** en formatos como **CSV** y **Parquet**.


## ğŸŒŸ Parte BÃ¡sica 

 - ğŸ“ Script 1:
 
	 - ğŸ”„ Se conecta a la API a intervalos regulares (cada 5 minutos).
	 
	  - ğŸ›‘ El script corre de manera continua hasta que se detenga manualmente.
	  
	  - ğŸ’¾ Obtiene los datos de la API y los almacena en una base de datos MongoDB en la colecciÃ³n "bicis".
	  
	 ***Funcionalidad***

	1.  ğŸ—„ï¸ **ConexiÃ³n con MongoDB**: Se conecta a la base de datos MongoDB en Atlas utilizando las credenciales y URI configuradas.
	
	2. ğŸŒ  **ObtenciÃ³n de datos**: Hace una solicitud a la API de CityBike y obtiene la respuesta en formato JSON.
	
	3.  ğŸ“¥ **Almacenamiento en MongoDB**: Los datos obtenidos se almacenan en una colecciÃ³n llamada `bicis` dentro de la base de datos `baseBicis`.

	4.  â° **Intervalo de ejecuciÃ³n**: El script se ejecuta cada 5 minutos (o el intervalo que se defina) utilizando la librerÃ­a `schedule`.
 - ğŸ› ï¸ Script 2:
 
	 - ğŸ–¥ï¸ Carga datos desde MongoDB a un DataFrame de pandas..
     
	 - ğŸ“¤ Exporta los siguientes campos: `id`, `name`, `timestamp`, `free_bikes`, `empty_slots`, `uid`, `last_updated`, `slots`, `normal_bikes`, `ebikes`.
	 
	- ğŸ› ï¸ Exporta los datos a los formatos:
			

		 - **CSV**
		 - **Parquet**
		 
	  ***Funcionalidad***

		1.  ğŸ—„ï¸ **ConexiÃ³n con MongoDB**: Se conecta a la base de datos MongoDB en Atlas utilizando las credenciales y URI configuradas.
	
		2. ğŸŒ  **ObtenciÃ³n de datos**: Hace una solicitud a la API de CityBike y obtiene la respuesta en formato JSON.
	
		3. ğŸ“¥  **Almacenamiento en MongoDB**: Los datos obtenidos se almacenan en una colecciÃ³n llamada `bicis` dentro de la base de datos `baseBicis`.

		4.  â° **Intervalo de ejecuciÃ³n**: El script se ejecuta cada 5 minutos (o el intervalo que se defina) utilizando la librerÃ­a `schedule`.

### ğŸ”§ Requisitos

#### ğŸ’» Requisitos del Sistema

 - **Python**
 
 - **MongoDB Atlas** para la base de datos (puedes usar un cluster gratuito).
 
 - **API de CityBike**: Proporciona informaciÃ³n sobre redes de bicicletas compartidas.

#### ğŸ“¦ LibrerÃ­as necesarias

Este proyecto requiere las siguientes librerÃ­as de Python:

    pip install pymongo pandas requests schedule pyarrow

 - **pymongo**: Para interactuar con la base de datos MongoDB.
 - **pandas**: Para el manejo y exportaciÃ³n de datos a **CSV** y **Parquet**.
 - **requests**: Para realizar las solicitudes HTTP a la API.
 - **schedule**: Para ejecutar el script a intervalos regulares.
 - **pyarrow**: Necesario para exportar datos a **Parquet**.

### ğŸ› ï¸ ConfiguraciÃ³n

#### ğŸ”‘ ConfiguraciÃ³n de MongoDB

Para usar MongoDB Atlas, primero debes crear una cuenta en [MongoDB Atlas](https://www.mongodb.com/cloud/atlas) y configurar un cluster. Luego, obtendrÃ¡s la URI de conexiÃ³n que se utilizarÃ¡ en el script.

ğŸ”— La URI de conexiÃ³n serÃ¡ algo similar a:

    MONGO_URI = "mongodb+srv://<username>:<password>@cluster0.mongodb.net/?retryWrites=true&w=majority"
Reemplaza `<username>` y `<password>` con tus credenciales de MongoDB Atlas.

#### ğŸŒ ConfiguraciÃ³n de la API

En este proyecto, se usa la API de CityBike, especÃ­ficamente la red de bicicletas de **A CoruÃ±a**:

    API_URL = "https://api.citybik.es/v2/networks/bicicorunha"
Este URL proporciona datos sobre las bicicletas disponibles, los espacios vacÃ­os, y otros detalles sobre la red de bicicletas.

## ğŸš€ Parte Avanzada

Este proyecto consiste en dockerizar un script de Python que interactÃºa con una base de datos MongoDB, desplegarlo en la nube utilizando OpenStack y automatizar su actualizaciÃ³n mediante GitHub. A continuaciÃ³n, se detallan los pasos para configurar y ejecutar el proyecto.


## ğŸ”§ Requisitos


1. ğŸ³ **Dockerizar el script para que se ejecute en un contenedor Docker.** 

2. ğŸ—„ï¸ **Utilizar un servidor MongoDB propio en un contenedor Docker.** 

3. ğŸš¢ **Publicar la imagen Docker en Docker Hub.**

4. â˜ï¸ **Desplegar la aplicaciÃ³n en la nube (OpenStack) con Docker.**

 5. ğŸ”„ **Automatizar la actualizaciÃ³n del contenedor Docker desde GitHub.**

## ğŸ› ï¸ Instrucciones

### ğŸ‹ 1. Dockerizar el Script de Python
Crea un archivo `Dockerfile` en el directorio del proyecto para construir la imagen Docker del script.

### ğŸ—„ï¸ 2. Configurar MongoDB en un Contenedor Docker

Utiliza un archivo `docker-compose.yml` para configurar la base de datos MongoDB junto con la aplicaciÃ³n Python.

Ejecuta el siguiente comando para levantar ambos servicios:

    docker-compose up --build


### ğŸš¢ 3. Publicar la Imagen Docker en Docker Hub

 1. ğŸ” Inicia sesiÃ³n en Docker Hub:

    docker login
  

 2. ğŸ—ï¸ Construye la imagen Docker:
 

    docker build -t <dockerhub_username>/python-app .
    

 3. ğŸ“¤ Sube la imagen al Docker Hub:
 
	 docker push <dockerhub_username>/python-app


### â˜ï¸ 4. Desplegar en la Nube con OpenStack
 1. ğŸ› ï¸ Configura Openstack
 
     -   ğŸ–¥ï¸ Crea una instancia de mÃ¡quina virtual.
     
	     -   ğŸ”‘ La instancia debe llevar tu nombre: por ejemplo, sbd-tu_nombre
    
			-   Escoge una imagen de instalaciÃ³n ubuntu22.04
    
			-   Utiliza un conjunto de reglas de firewall ajustado: por ejemplo, open4all
    
			-   AÃ±ade tu llave RSA, asÃ­ como la llave RSA del profesor (para que tambien el tenga acceso)
    
			-   Instala docker en tu mÃ¡quina virtual siguiendo las instrucciones que tienes mas abajo
    
			-   AsegÃºrate de que tienes acceso a la mÃ¡quina virtual en la nube
     
	-   ğŸŒ Acceso a la mÃ¡quina virtual en la nube.
	
		   Para acceder Ã¡s mÃ¡quinas virtuais (por ssh) tes dÃºas opciÃ³ns:

		1. Activar a VPN ao CESGA

		2. Realizar un salto sobre unha mÃ¡quina intermedia.

  

			Desde tu pc local en la clase tienes acceso a la mÃ¡quina hadoop.cesga.es y en esa mÃ¡quina tienes acceso a las mÃ¡quinas virtuales, por lo que puedes hacer un SSH Jump.

			En lugar de conectarte Ã¡ mÃ¡quina destino directamente con:

			`ssh cesgaxuser@ip_mÃ¡quina_virtual`

			utiliza un ssh jump

			`ssh -J usuario_hadoop@hadoop.cesga.es cesgaxuser@ip_mÃ¡quina_virtual
`

 - ğŸš€ Desplegar contenedores en OpenStack:
 
	
	 - Copia el archivo `docker-compose.yml` al servidor. 
	 
	 - 	 Ejecuta los siguientes comandos para iniciar los servicios:
		
				docker-compose up --build -d

 3.  :triangular_ruler: CÃ¡lculo del nÃºmero de documentos

	 - Suponiendo que la API consulta datos cada 5 minutos durante las vacaciones:
					 
			DÃ­as de vacaciones: N
			Total de documentos = (24 horas * 12 consultas/hora) * N dÃ­as * 49 documentos por consulta.

### 5. ğŸ”„ Automatizar Actualizaciones desde GitHub

Es posible configurar una automatizaciÃ³n en GitHub para que la imagen se construya con cada nuevo push al repositorio y automÃ¡ticamente se envÃ­e al registro (hub.docker.com).

 - **Pasos necesarios:**
 
	1.  ğŸ”‘ Crear un token de acceso para GitHub en Docker Hub.
	
	2.  ğŸ”§ Configurar las credenciales de acceso GitHub >> Docker Hub.
	
	3.  ğŸ“œ Definir un Workflow que construya la imagen y la envÃ­e al registro.

- **Crear token de acceso en Docker Hub**

	Docker Hub:  
Ir a **My Account > Security > New Access Token**.

- **Configurar credenciales en GitHub**

	Repositorio de GitHub:  
Ir a **Settings > Secrets and Variables > Actions > Repository Secrets** y aÃ±adir:

	-   `DOCKER_USERNAME`: nombre_de_usuario_hub
	-   `DOCKERHUB_TOKEN`: token_hub
- **Configurar Workflow en GitHub**

En el repositorio, ir a **Actions > Set up a workflow 		yourself** y definir el siguiente archivo YAML:

    name: ci
    on: 
	    push: 
		    branches: 
			    - main
	jobs: 
		build: 
			runs-on: ubuntu-latest
			steps: 
				- 
					name: Checkout
					uses: actions/checkout@v4
				- 
					name: Login to Docker Hub
					uses: docker/login-action@v3
					with:
						username: ${{ secrets.DOCKER_USERNAME }} 
						password: ${{ secrets.DOCKERHUB_TOKEN }}
				- 
					name: Set up Docker Buildx
					uses: docker/setup-buildx-action@v3
				- 
					name: Build and push
					uses: docker/build-push-action@v5
					with: 
     					context: . 
						push: true 
						tags: ${{ secrets.DOCKER_USERNAME }}/${{ github.event.repository.name }}:latest
### ğŸ‰ Funcionamiento

-   ğŸš€ El Workflow se ejecutarÃ¡ automÃ¡ticamente y una nueva imagen creada con el cÃ³digo actual del repositorio serÃ¡ enviada al registro de Docker Hub.
-   ğŸŒ Ante cada nuevo push al repositorio, el Workflow volverÃ¡ a ejecutarse, actualizando la imagen en Docker Hub con la Ãºltima versiÃ³n del cÃ³digo.
-    â˜ï¸ La aplicaciÃ³n desplegada en OpenStack estarÃ¡ siempre actualizada, lista para procesar los datos y exportarlos en diferentes formatos.

### ğŸŒˆ ConclusiÃ³n y PrÃ³ximos Pasos
Este proyecto combina la automatizaciÃ³n, la escalabilidad en la nube y el manejo eficiente de datos. Es una excelente base para expandir funcionalidades como:

1. AÃ±adir alertas en tiempo real: Configurar notificaciones por correo o Slack para cambios en los datos.
 
2. AnÃ¡lisis avanzado: Implementar algoritmos de Machine Learning para predecir la disponibilidad de bicicletas.
 
3. IntegraciÃ³n con dashboards: Usar herramientas como Power BI o Tableau para crear paneles interactivos.
 
ğŸš€ Â¡Adelante! Este es solo el comienzo de un sistema robusto para el manejo de datos en tiempo real.






